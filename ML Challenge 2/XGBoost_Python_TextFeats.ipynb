{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is created and shared to help people learn and understand the process of solving a problem which involves text variables. Apart from creating new variables, you'll learn to extract ~650 text (count) features and use them in training a xgboost model. This script scores ~0.70 on public leaderboard.\n",
    "For any questions, feel free to raise issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "mingw_path = 'C:\\\\Program Files\\\\mingw-w64\\\\x86_64-6.3.0-posix-seh-rt_v5-rev1\\\\mingw64\\\\bin'\n",
    "os.environ['PATH'] = mingw_path + ';' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import xgboost as xgb\n",
    "\n",
    "pd.set_option('display.max_colwidth',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert unix time format\n",
    "unix_cols = ['deadline','state_changed_at','launched_at','created_at']\n",
    "\n",
    "for x in unix_cols:\n",
    "    train[x] = train[x].apply(lambda k: datetime.datetime.fromtimestamp(int(k)).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "    test[x] = test[x].apply(lambda k: datetime.datetime.fromtimestamp(int(k)).strftime('%Y-%m-%d %H:%M:%S'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_use = ['name','desc']\n",
    "len_feats = ['name_len','desc_len']\n",
    "count_feats = ['name_count','desc_count']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    train[len_feats[i]] = train[cols_to_use[i]].apply(str).apply(len)\n",
    "    test[len_feats[i]] = test[cols_to_use[i]].apply(str).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['name_count'] = train['name'].str.split().str.len()\n",
    "train['desc_count'] = train['desc'].str.split().str.len()\n",
    "\n",
    "test['name_count'] = test['name'].str.split().str.len()\n",
    "test['desc_count'] = test['desc'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['keywords_len'] = train['keywords'].str.len()\n",
    "train['keywords_count'] = train['keywords'].str.split('-').str.len()\n",
    "\n",
    "test['keywords_len'] = test['keywords'].str.len()\n",
    "test['keywords_count'] = test['keywords'].str.split('-').str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converting string variables to datetime\n",
    "unix_cols = ['deadline','state_changed_at','launched_at','created_at']\n",
    "\n",
    "for x in unix_cols:\n",
    "    train[x] = train[x].apply(lambda k: datetime.datetime.strptime(k, '%Y-%m-%d %H:%M:%S'))\n",
    "    test[x] = test[x].apply(lambda k: datetime.datetime.strptime(k, '%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# there should be simpler way - might take longer\n",
    "# creating list with time difference between 1) launched_at and created_at 2) deadline and launched_at\n",
    "\n",
    "time1 = []\n",
    "time3 = []\n",
    "time0 = []\n",
    "for i in np.arange(train.shape[0]):\n",
    "    time1.append(np.round((train.loc[i, 'launched_at'] - train.loc[i, 'created_at']).total_seconds()).astype(int))\n",
    "    time3.append(np.round((train.loc[i, 'deadline'] - train.loc[i, 'launched_at']).total_seconds()).astype(int))\n",
    "    time0.append(np.round((train.loc[i, 'state_changed_at'] - train.loc[i, 'deadline']).total_seconds()).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['time1'] = np.log(time1)\n",
    "train['time3'] = np.log(time3)\n",
    "train['time0'] = np.log(time0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for test data\n",
    "time5 = []\n",
    "time6 = []\n",
    "time7 = []\n",
    "for i in np.arange(test.shape[0]):\n",
    "    time5.append(np.round((test.loc[i, 'launched_at'] - test.loc[i, 'created_at']).total_seconds()).astype(int))\n",
    "    time6.append(np.round((test.loc[i, 'deadline'] - test.loc[i, 'launched_at']).total_seconds()).astype(int))\n",
    "    time7.append(np.round((test.loc[i, 'state_changed_at'] - test.loc[i, 'deadline']).total_seconds()).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['time1'] = np.log(time5)\n",
    "test['time3'] = np.log(time6)\n",
    "test['time0'] = np.log(time7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat = ['disable_communication','country']\n",
    "\n",
    "for x in feat:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train[x].values) + list(test[x].values))\n",
    "    train[x] = le.transform(list(train[x]))\n",
    "    test[x] = le.transform(list(test[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['goal'] = np.log1p(train['goal'])\n",
    "test['goal'] = np.log1p(test['goal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creating a full list of descriptions from train and etst\n",
    "kickdesc = pd.Series(train['desc'].tolist() + test['desc'].tolist()).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this function cleans punctuations, digits and irregular tabs. Then converts the sentences to lower\n",
    "def desc_clean(word):\n",
    "    p1 = re.sub(pattern='(\\W+)|(\\d+)|(\\s+)',repl=' ',string=word)\n",
    "    p1 = p1.lower()\n",
    "    return p1\n",
    "\n",
    "kickdesc = kickdesc.map(desc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "kickdesc = [[x for x in x.split() if x not in stop] for x in kickdesc]\n",
    "\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "kickdesc = [[stemmer.stem(x) for x in x] for x in kickdesc]\n",
    "\n",
    "kickdesc = [[x for x in x if len(x) > 2] for x in kickdesc]\n",
    "\n",
    "kickdesc = [' '.join(x) for x in kickdesc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Count Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Due to memory error, limited the number of features to 650\n",
    "cv = CountVectorizer(max_features=650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alldesc = cv.fit_transform(kickdesc).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a data frame\n",
    "combine = pd.DataFrame(alldesc)\n",
    "combine.rename(columns= lambda x: 'variable_'+ str(x), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the text features\n",
    "\n",
    "train_text = combine[:train.shape[0]]\n",
    "test_text = combine[train.shape[0]:]\n",
    "\n",
    "test_text.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing train and test data before merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols_to_use = ['name_len','desc_len','keywords_len','name_count','desc_count','keywords_count','time1','time3','time0','goal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = train['final_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = train.loc[:,cols_to_use]\n",
    "test = test.loc[:,cols_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([train, train_text],axis=1)\n",
    "X_test = pd.concat([test, test_text],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108129, 660)\n",
      "(63465, 660)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name_len', 'desc_len', 'keywords_len', 'name_count', 'desc_count',\n",
       "       'keywords_count', 'time1', 'time3', 'time0', 'goal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id = pd.read_csv('test.csv')\n",
    "test_id = test_id['project_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(learning_rate =0.025, n_estimators=1000, max_depth=6,\n",
    "                    min_child_weight=5, gamma=0.01, subsample=0.7, colsample_bytree=0.7,\n",
    "                    objective= 'binary:logistic', nthread=4, seed=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=0.01, learning_rate=0.025,\n",
       "       max_delta_step=0, max_depth=6, min_child_weight=5, missing=None,\n",
       "       n_estimators=1000, nthread=4, objective='binary:logistic',\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=2017,\n",
       "       silent=True, subsample=0.7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'project_id':test_id,'final_status':pred})\n",
    "submission = submission[['project_id','final_status']]\n",
    "submission.to_csv(\"xgb.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>project_id</th>\n",
       "      <th>final_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kkst917493670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kkst1664901914</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kkst925125077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kkst1427645275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kkst1714249266</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       project_id  final_status\n",
       "0   kkst917493670             0\n",
       "1  kkst1664901914             0\n",
       "2   kkst925125077             0\n",
       "3  kkst1427645275             0\n",
       "4  kkst1714249266             0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
